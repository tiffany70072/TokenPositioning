{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4/13: Generate fake numpy files for testing.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_type = encoder_train, data_shape = [100, 8]\n",
      "data_type = decoder_train, data_shape = [100, 8]\n",
      "data_type = encoder_valid, data_shape = [50, 8]\n",
      "data_type = decoder_valid, data_shape = [50, 8]\n"
     ]
    }
   ],
   "source": [
    "# Generate fake data.\n",
    "\n",
    "data_path = \"../data/\"\n",
    "data_name = \"fake-data\"\n",
    "data_type_list = ['encoder_train', 'decoder_train', 'encoder_valid', 'decoder_valid']\n",
    "data_shape_list = [[100, 8], [100, 8], [50, 8], [50, 8]]\n",
    "\n",
    "os.mkdir(os.path.join(data_path, data_name))  # Make directory.\n",
    "\n",
    "for data_type, data_shape in zip(data_type_list, data_shape_list):\n",
    "    print(\"data_type = %s, data_shape =\" % data_type, data_shape)\n",
    "    npy_file = np.ones(data_shape)\n",
    "    np.save(\"%s%s/%s.npy\" % (data_path, data_name, data_type), npy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake data.\n",
    "\n",
    "data_path = \"../data/\"\n",
    "data_name = \"fake-data\"\n",
    "\n",
    "#os.mkdir(os.path.join(data_path, data_name))  # Make directory.\n",
    "\n",
    "encoder_train = np.array([[1, 3, 3, 3, 3, 2],\n",
    "                          [0, 1, 3, 3, 3, 2], \n",
    "                         [0, 0, 1, 3, 3, 2],\n",
    "                         [0, 0, 0, 1, 3, 2],\n",
    "                         [1, 4, 4, 4, 4, 2],\n",
    "                         [0, 1, 4, 4, 4, 2],\n",
    "                         [0, 0, 1, 4, 4, 2],\n",
    "                         [0, 0, 0, 1, 4, 2]])\n",
    "decoder_train = np.array([[1, 5, 5, 5, 3, 2],\n",
    "                          [1, 5, 5, 3, 2, 0], \n",
    "                         [1, 5, 3, 2, 0, 0],\n",
    "                         [1, 3, 2, 0, 0, 0],\n",
    "                         [1, 5, 5, 5, 4, 2],\n",
    "                         [1, 5, 5, 4, 2, 0],\n",
    "                         [1, 5, 4, 2, 0, 0],\n",
    "                         [1, 4, 2, 0, 0, 0]])\n",
    "encoder_valid = np.copy(encoder_train)\n",
    "decoder_valid = np.copy(decoder_train)\n",
    "np.save(\"%s%s/encoder_train.npy\" % (data_path, data_name), encoder_train)\n",
    "np.save(\"%s%s/decoder_train.npy\" % (data_path, data_name), decoder_train)\n",
    "np.save(\"%s%s/encoder_valid.npy\" % (data_path, data_name), encoder_valid)\n",
    "np.save(\"%s%s/decoder_valid.npy\" % (data_path, data_name), decoder_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test src/main.py with task = \"autoenc-last\":\n",
    "# In src/, run $ python3 main.py --task=autoenc-last --units=10 --max_epochs=1 --mode=train --data_name=fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 ? -> 1.0\n",
      "0.0 ? -> 0.0\n",
      "1.0 ? -> 1.0\n",
      "0.0 ? -> 0.0\n",
      "0.5 ? -> 0.5\n"
     ]
    }
   ],
   "source": [
    "# Test evaluate_autoencoder_last_step.\n",
    "\n",
    "import evaluator\n",
    "import importlib\n",
    "importlib.reload(evaluator)\n",
    "\n",
    "real = np.array([[3, 3, 3, 2, 0, 0]])  # 0: PAD, 2: EOS, 3, 4: vocab\n",
    "pred = np.array([[3, 3, 3, 2, 0, 0]])\n",
    "acc = evaluator.evaluate_autoencoder_last_step(real, pred)\n",
    "print(\"1.0 ? ->\", acc)\n",
    "\n",
    "real = np.array([[3, 3, 3, 2, 0, 0]])  # The last words are different.\n",
    "pred = np.array([[3, 3, 4, 2, 0, 0]])\n",
    "acc = evaluator.evaluate_autoencoder_last_step(real, pred)\n",
    "print(\"0.0 ? ->\", acc)\n",
    "\n",
    "\n",
    "real = np.array([[3, 3, 3, 2, 0, 0]])  # Other words are different.\n",
    "pred = np.array([[4, 4, 3, 2, 0, 0]])\n",
    "acc = evaluator.evaluate_autoencoder_last_step(real, pred)\n",
    "print(\"1.0 ? ->\", acc)\n",
    "\n",
    "\n",
    "real = np.array([[3, 3, 3, 2, 0, 0]])  # Every word are same, but last word appear at wrong t.\n",
    "pred = np.array([[3, 3, 3, 3, 2, 2]])\n",
    "acc = evaluator.evaluate_autoencoder_last_step(real, pred)\n",
    "print(\"0.0 ? ->\", acc)\n",
    "\n",
    "\n",
    "real = np.array([[3, 3, 3, 2, 0, 0], [3, 3, 3, 2, 0, 0]])  \n",
    "pred = np.array([[3, 3, 3, 3, 2, 2], [4, 4, 3, 2, 0, 0]])\n",
    "acc = evaluator.evaluate_autoencoder_last_step(real, pred)\n",
    "print(\"0.5 ? ->\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
