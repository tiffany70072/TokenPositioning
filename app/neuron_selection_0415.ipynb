{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_path = ../result/auto-last-toy_units=32_seed=2\n",
      "WARNING:tensorflow:From /home/eating/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From ../src/build_model.py:6: The name tf.keras.initializers.RandomUniform is deprecated. Please use tf.compat.v1.keras.initializers.RandomUniform instead.\n",
      "\n",
      "get_data\n",
      "(Load data) token_size  = 6 6\n",
      "WARNING:tensorflow:From /home/eating/.local/lib/python3.5/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/eating/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_inputs (InputLayer)  [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "encoder_emb (Embedding)      (None, None, 32)          192       \n",
      "_________________________________________________________________\n",
      "forward (GRU)                [(None, None, 32), (None, 6240      \n",
      "=================================================================\n",
      "Total params: 6,432\n",
      "Trainable params: 6,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_emb (Embedding)         multiple             192         decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               multiple             6240        decoder_emb[15][0]               \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output_dense (Dense)            multiple             198         decoder_gru[15][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,630\n",
      "Trainable params: 6,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\tmode=analysis, units=32, model_path=../saved_model/auto-last-toy_units=32_seed=2\n",
      "\t (26000, 15) (26000, 15)\n",
      "\twhole accuracy=1.0000, each accuracy=1.0000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4/15: \n",
    "Neuron selection for (1) store (2) counter (3) ig\n",
    "Neuron verification on these two tasks.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "matplotlib.use('GTK')\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "\n",
    "import call_classifier\n",
    "import call_integrated_gradient as call_ig\n",
    "import evaluator\n",
    "import sample_getter\n",
    "import state_getter\n",
    "import utils \n",
    "import verification\n",
    "from neuron_mapping import evaluate_intersection\n",
    "from neuron_mapping import get_intersection\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "\n",
    "task = 'autoenc-last'\n",
    "data_name = 'auto-last-toy'\n",
    "units = 32\n",
    "random_seed = 2\n",
    "token = 3\n",
    "saved_path = os.path.join('../result/', \"%s_units=%d_seed=%d\" % (data_name, units, random_seed))\n",
    "                         # 'neuron_selection_token=%d' % token)\n",
    "print('saved_path =', saved_path)\n",
    "target_units = units // 2\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(os.path.join(saved_path))  # Make directory.\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "seq2seq = utils.get_trained_model(task, data_name, units, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_neuron(token, T_list): \n",
    "    print(\"\\tGet Store\")\n",
    "    #print(\"Token %d (%s)\" % (token, seq2seq.tgt_itoc[token]))\n",
    "    result = {}\n",
    "    for T in T_list:\n",
    "        print(\"=\" * 50 + \"\\nT = %d\" % T)\n",
    "        si1 = sample_getter.get_sample_by_one_condition(seq2seq.decoder_in_test, \n",
    "                                                        token=token, position=T, N=1000)\n",
    "        si2 = sample_getter.get_sample_by_one_condition(seq2seq.decoder_in_test, \n",
    "                                                        token=token, position=T, N=1000, \n",
    "                                                        except_this_token=True)    \n",
    "        sample_index = sample_getter.get_different_amount_sample([si1, si2])\n",
    "        if sample_index is None or sample_index.shape[1] < 5:\n",
    "            print(\"\\tToo less samples in this condition.\")\n",
    "            continue  # No any sample for this condition.\n",
    "        \n",
    "        result[T] = {}\n",
    "        state = state_getter.get_hidden_state(seq2seq, sample_index)\n",
    "        for t in range(T+2):\n",
    "            print(\"=\" * 50 + \"\\nt = %d\" % t)\n",
    "            x = state[:, :, t, :]\n",
    "            y = np.concatenate([np.full([x.shape[1]], 1, dtype=int), np.full([x.shape[1]], 0, dtype=int)])\n",
    "            x = np.reshape(x, [-1, seq2seq.units])\n",
    "            x, y = shuffle(x, y, random_state=42)\n",
    "            features = call_classifier.call_recursive_rfe(x, y, max_count=target_units, one_threshold=0.5)\n",
    "            result[T][t] = features\n",
    "            print(\"features =\", features)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counter_neuron(token, T_list):\n",
    "    print(\"\\tGet Counter\")\n",
    "    #print(\"Token %d (%s)\" % (token, seq2seq.tgt_itoc[token])) \n",
    "    result = {}\n",
    "    for T in T_list:\n",
    "        print(\"=\" * 50 + \"\\nT = %d\" % T)\n",
    "        si = sample_getter.get_sample_by_one_condition(seq2seq.decoder_in_test, \n",
    "                                                       token=token, position=T, N=1000)\n",
    "        sample_index = sample_getter.get_different_amount_sample([si])\n",
    "        if sample_index is None or sample_index.shape[1] < 5:\n",
    "            print(\"\\tToo less samples in this condition.\")\n",
    "            return  # No any sample for this condition.\n",
    "        state = state_getter.get_hidden_state(seq2seq, sample_index)\n",
    "        state = state[:, :, :T]\n",
    "\n",
    "        x = state[0].transpose([1, 0, 2])  # [N, t, units] -> [t, N, units]\n",
    "        y = np.full([x.shape[1]], 0, dtype=int)\n",
    "        for t in range(1, x.shape[0]):\n",
    "            y = np.concatenate([y, np.full([x.shape[1]], t, dtype=int)])  \n",
    "        x = np.reshape(x, [-1, seq2seq.units])\n",
    "        x, y = shuffle(x, y, random_state=42)\n",
    "        result[T] = call_classifier.call_recursive_rfe(x, y, max_count=target_units, one_threshold=0.5)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ig_neuron(token, T_list):\n",
    "    print(\"\\tGet IG\")\n",
    "    #print(\"Token %d (%s)\" % (token, seq2seq.tgt_itoc[token]))\n",
    "    result = {}\n",
    "    for T in T_list:\n",
    "        print(\"=\" * 50 + \"\\nT = %d\" % T)\n",
    "        si1 = sample_getter.get_sample_by_one_condition(seq2seq.decoder_in_test, \n",
    "                                                        token=token, position=T, N=1000)\n",
    "        result[T] = {}\n",
    "        decoder_states, decoder_inputs = call_ig.get_state_by_sample_index(seq2seq, si1)\n",
    "        for t in range(T+1):\n",
    "            print(\"=\" * 50 + \"\\nt = %d\" % t)\n",
    "            decoder_model = call_ig.get_model_without_argmax(seq2seq, input_t=t, output_t=T)\n",
    "            score = call_ig.compute_ig_steps(decoder_model, decoder_states[t], decoder_inputs, target_class=token)\n",
    "            selected = call_ig.get_important_neurons_by_IG(score, k=target_units)\n",
    "            result[T][t] = selected\n",
    "            print(\"\\tselected =\", selected)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGet Store\n",
      "==================================================\n",
      "T = 5\n",
      "\tFind 1000 samples with token==3 and position=5.\n",
      "\tFind 1000 samples with token!=3 and position=5.\n",
      "\t(Hidden value) container.shape = (2, 1000, 15, 32)\n",
      "==================================================\n",
      "t = 0\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [1, 2, 4, 7, 13, 17, 22, 27, 3, 9, 12, 15, 18, 21, 23, 25]\n",
      "==================================================\n",
      "t = 1\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [2, 4, 7, 13, 15, 17, 18, 23, 1, 6, 14, 22, 24, 26, 27, 28]\n",
      "==================================================\n",
      "t = 2\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [2, 8, 9, 15, 17, 20, 21, 23, 0, 4, 7, 16, 25, 29, 30, 31]\n",
      "==================================================\n",
      "t = 3\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [0, 4, 8, 16, 20, 21, 25, 31, 2, 7, 9, 11, 17, 22, 29, 30]\n",
      "==================================================\n",
      "t = 4\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [0, 4, 8, 9, 20, 21, 25, 30, 2, 10, 11, 16, 22, 24, 29, 31]\n",
      "==================================================\n",
      "t = 5\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [8, 11, 17, 20, 21, 22, 24, 25, 0, 9, 10, 15, 16, 23, 30, 31]\n",
      "==================================================\n",
      "t = 6\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [1, 2, 11, 15, 16, 17, 23, 31, 8, 9, 13, 14, 20, 22, 25, 29]\n",
      "==================================================\n",
      "T = 7\n",
      "\tFind 1000 samples with token==3 and position=7.\n",
      "\tFind 1000 samples with token!=3 and position=7.\n",
      "\t(Hidden value) container.shape = (2, 1000, 15, 32)\n",
      "==================================================\n",
      "t = 0\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [2, 4, 7, 13, 17, 18, 22, 27, 1, 3, 6, 9, 14, 15, 23, 25]\n",
      "==================================================\n",
      "t = 1\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [2, 7, 13, 15, 17, 22, 23, 27, 1, 3, 4, 6, 14, 18, 26, 28]\n",
      "==================================================\n",
      "t = 2\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [2, 8, 9, 15, 17, 20, 21, 23, 0, 4, 7, 16, 25, 27, 30, 31]\n",
      "==================================================\n",
      "t = 3\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [0, 4, 8, 16, 21, 25, 30, 31, 2, 7, 9, 11, 17, 20, 27, 29]\n",
      "==================================================\n",
      "t = 4\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [0, 4, 8, 9, 20, 21, 25, 30, 2, 7, 11, 16, 23, 24, 29, 31]\n",
      "==================================================\n",
      "t = 5\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [0, 4, 8, 9, 20, 21, 25, 30, 2, 7, 11, 16, 23, 24, 29, 31]\n",
      "==================================================\n",
      "t = 6\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [0, 4, 8, 9, 20, 21, 24, 30, 2, 7, 10, 11, 22, 25, 29, 31]\n",
      "==================================================\n",
      "t = 7\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [8, 9, 17, 20, 21, 22, 24, 30, 0, 4, 5, 10, 11, 15, 23, 25]\n",
      "==================================================\n",
      "t = 8\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "features = [1, 11, 15, 16, 17, 23, 25, 31, 2, 8, 9, 13, 14, 18, 20, 22]\n",
      "\tGet Counter\n",
      "==================================================\n",
      "T = 5\n",
      "\tFind 1000 samples with token==3 and position=5.\n",
      "\t(Hidden value) container.shape = (1, 1000, 15, 32)\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "==================================================\n",
      "T = 7\n",
      "\tFind 1000 samples with token==3 and position=7.\n",
      "\t(Hidden value) container.shape = (1, 1000, 15, 32)\n",
      "\tcount = 8, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tcount = 16, \t(RFE, one) Train accuracy = 1.000, \tTest accuracy = 1.000\n",
      "\tGet IG\n",
      "==================================================\n",
      "T = 5\n",
      "\tFind 1000 samples with token==3 and position=5.\n",
      "==================================================\n",
      "t = 0\n",
      "\n",
      "\tCross step. input_t = 0, output_t = 5\n",
      "\tClass index = 3\n",
      "\tselected = [30, 1, 0, 24, 11, 20, 4, 13, 18, 27, 22, 7, 6, 21, 29, 3]\n",
      "==================================================\n",
      "t = 1\n",
      "\n",
      "\tCross step. input_t = 1, output_t = 5\n",
      "\tClass index = 3\n",
      "\tselected = [30, 1, 0, 11, 4, 20, 24, 13, 18, 7, 29, 6, 27, 15, 22, 10]\n",
      "==================================================\n",
      "t = 2\n",
      "\n",
      "\tCross step. input_t = 2, output_t = 5\n",
      "\tClass index = 3\n",
      "\tselected = [30, 0, 1, 11, 4, 20, 13, 3, 29, 18, 21, 15, 2, 7, 6, 10]\n",
      "==================================================\n",
      "t = 3\n",
      "\n",
      "\tCross step. input_t = 3, output_t = 5\n",
      "\tClass index = 3\n",
      "\tselected = [30, 0, 1, 11, 4, 3, 2, 17, 24, 29, 13, 21, 22, 20, 18, 10]\n",
      "==================================================\n",
      "t = 4\n",
      "\n",
      "\tCross step. input_t = 4, output_t = 5\n",
      "\tClass index = 3\n",
      "\tselected = [30, 0, 11, 3, 27, 22, 21, 2, 24, 1, 29, 20, 23, 25, 26, 31]\n",
      "==================================================\n",
      "t = 5\n",
      "\n",
      "\tCross step. input_t = 5, output_t = 5\n",
      "\tClass index = 3\n",
      "\tselected = [23, 17, 15, 5, 27, 11, 14, 22, 30, 3, 0, 19, 8, 21, 7, 20]\n",
      "==================================================\n",
      "T = 7\n",
      "\tFind 1000 samples with token==3 and position=7.\n",
      "==================================================\n",
      "t = 0\n",
      "\n",
      "\tCross step. input_t = 0, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [30, 1, 0, 27, 18, 7, 22, 6, 13, 24, 3, 20, 11, 4, 21, 29]\n",
      "==================================================\n",
      "t = 1\n",
      "\n",
      "\tCross step. input_t = 1, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [30, 1, 0, 27, 13, 18, 20, 7, 6, 22, 24, 11, 4, 29, 3, 21]\n",
      "==================================================\n",
      "t = 2\n",
      "\n",
      "\tCross step. input_t = 2, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [30, 1, 0, 13, 11, 20, 18, 4, 6, 7, 27, 29, 22, 24, 15, 26]\n",
      "==================================================\n",
      "t = 3\n",
      "\n",
      "\tCross step. input_t = 3, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [30, 1, 0, 11, 4, 13, 18, 20, 6, 3, 7, 29, 15, 27, 26, 21]\n",
      "==================================================\n",
      "t = 4\n",
      "\n",
      "\tCross step. input_t = 4, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [30, 1, 0, 11, 3, 4, 13, 20, 18, 29, 24, 6, 15, 2, 21, 7]\n",
      "==================================================\n",
      "t = 5\n",
      "\n",
      "\tCross step. input_t = 5, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [30, 0, 1, 11, 4, 3, 24, 13, 2, 17, 29, 22, 18, 21, 20, 14]\n",
      "==================================================\n",
      "t = 6\n",
      "\n",
      "\tCross step. input_t = 6, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [30, 0, 3, 11, 27, 22, 2, 21, 24, 23, 26, 1, 25, 31, 9, 20]\n",
      "==================================================\n",
      "t = 7\n",
      "\n",
      "\tCross step. input_t = 7, output_t = 7\n",
      "\tClass index = 3\n",
      "\tselected = [23, 15, 17, 5, 27, 11, 22, 30, 3, 0, 8, 19, 21, 14, 16, 20]\n"
     ]
    }
   ],
   "source": [
    "T_list = [5, 7]\n",
    "store_neuron = get_store_neuron(token, T_list)\n",
    "counter_neuron = get_counter_neuron(token, T_list)\n",
    "ig_neuron = get_ig_neuron(token, T_list)\n",
    "\n",
    "with open(os.path.join(saved_path, 'neuron_token=%d.pickle' % token), 'wb') as handle:\n",
    "    data = {'store': store_neuron,\n",
    "           'counter': counter_neuron,\n",
    "           'ig': ig_neuron}\n",
    "    pickle.dump(data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the accuracy of original task to compare with the result after replacement of the important neurons.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def verify_original_model(seq2seq, sample, real, token, T):\n",
    "    print(\"\\tVerify on original model.\")\n",
    "    pred = seq2seq.inference_batch(sample)\n",
    "    pred = pad_sequences(pred, maxlen=seq2seq.tgt_max_len, padding='post', truncating='post')\n",
    "    print(pred[:3])\n",
    "    print(\"\", end=\"\\t\")\n",
    "    evaluator.evaluate_autoencoder_at_time(real, pred, time_step=T, verbose=2)  \n",
    "    evaluator.evaluate_autoencoder_token(real, pred, token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\tFind 100 samples with token==3 and position=5.\n",
      "\tVerify on original model.\n",
      "[[5 5 5 5 3 2 0 0 0 0 0 0 0 0 0]\n",
      " [5 5 5 5 3 2 0 0 0 0 0 0 0 0 0]\n",
      " [5 5 5 5 3 2 0 0 0 0 0 0 0 0 0]]\n",
      "\t(t=5)\t1.0000\t1.0000\t1.0000\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "T=5\tt=1\tN1=16\tN2=16\tN=10\tjac=0.45\t\n",
      "\t\t\tdisable\t(t=5)\t0.5000\t0.0000\t1.0000\n",
      "\t\t\tenable\t[[5. 5. 5. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [5. 5. 5. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [5. 5. 5. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]]\n",
      "(t=5)\t0.7500\t0.0000\t1.0000\n",
      "T=5\tt=2\tN1=16\tN2=16\tN=9\tjac=0.39\t\n",
      "\t\t\tdisable\t(t=5)\t0.7500\t0.0000\t1.0000\n",
      "\t\t\tenable\t[[5. 5. 5. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [5. 5. 5. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [5. 5. 5. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]]\n",
      "(t=5)\t0.7500\t0.0000\t1.0000\n",
      "T=5\tt=4\tN1=16\tN2=16\tN=11\tjac=0.52\t\n",
      "\t\t\tdisable\t(t=5)\t1.0000\t0.3800\t1.0000\n",
      "\t\t\tenable\t[[5. 5. 5. 5. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [5. 5. 5. 5. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [5. 5. 5. 5. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]]\n",
      "(t=5)\t1.0000\t1.0000\t1.0000\n"
     ]
    }
   ],
   "source": [
    "# Verify store neurons\n",
    "\n",
    "\n",
    "def verify_store_one_step(T, t, feature1, feature2, seq2seq, sample, real):\n",
    "    # Enable and disable store neuron and calculate the accuracy.\n",
    "    print(\"T=%d\\tt=%d\\tN1=%d\\tN2=%d\" % (T, t, len(feature1), len(feature2)), end=\"\\t\")\n",
    "    evaluate_intersection(feature1, feature2, verbose=2)\n",
    "    feature = get_intersection(feature1, feature2)\n",
    "    print(\"\\n\\t\\t\\t\", end=\"\")\n",
    "    pred = verification.verify_decoder(seq2seq, sample, feature, time_step=t, \n",
    "                                       mode=\"disable\", replace_by=\"zero\", verbose=2)\n",
    "    evaluator.evaluate_autoencoder_at_time(real, pred, time_step=T, verbose=2) \n",
    "    print(\"\\t\\t\\t\", end=\"\")\n",
    "    pred = verification.verify_decoder(seq2seq, sample, feature, time_step=t, \n",
    "                                       mode=\"enable\", replace_by=\"zero\", verbose=2) \n",
    "    print(pred[:3])\n",
    "    evaluator.evaluate_autoencoder_at_time(real, pred, time_step=T, verbose=2) \n",
    "\n",
    "    \n",
    "def verify_store_one_token(token):\n",
    "    with open(os.path.join(saved_path, 'neuron_token=%d.pickle' % token), 'rb') as handle:\n",
    "        result = pickle.load(handle)\n",
    "        store_neuron = result['store']\n",
    "        ig_neuron = result['ig']\n",
    "        \n",
    "    for T in ig_neuron:\n",
    "        print(\"-\" * 50)\n",
    "        si1 = sample_getter.get_sample_by_one_condition(seq2seq.decoder_in_test, \n",
    "                                                        token=token, position=T, N=100)\n",
    "        sample = seq2seq.encoder_in_test[si1]\n",
    "        real = evaluator.get_evaluate_real(seq2seq, si1)\n",
    "        verify_original_model(seq2seq, sample, real, token, T)\n",
    "        for t in [1, 2, 4]: #ig_neuron[T]:\n",
    "            #t = 3\n",
    "            verify_store_one_step(T, t, store_neuron[T][t], ig_neuron[T][t], seq2seq, sample, real)\n",
    "            \n",
    "        break\n",
    "\n",
    "verify_store_one_token(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFind 100 samples with token==3 and position=5.\n",
      "\tVerify on original model.\n",
      "[[5 5 5 5 3 2 0 0 0 0 0 0 0 0 0]\n",
      " [5 5 5 5 3 2 0 0 0 0 0 0 0 0 0]\n",
      " [5 5 5 5 3 2 0 0 0 0 0 0 0 0 0]]\n",
      "\t(t=5)\t1.0000\t1.0000\t1.0000\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "T=5\tt=0\tN1=16\tN2=16\tN=10\tjac=0.45\t\n",
      "\tdisable\t(t=5)\t1.0000\t1.0000\t1.0000\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "T=5\tt=1\tN1=16\tN2=16\tN=10\tjac=0.45\t\n",
      "\tdisable\t(t=5)\t1.0000\t1.0000\t1.0000\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "T=5\tt=2\tN1=16\tN2=16\tN=9\tjac=0.39\t\n",
      "\tdisable\t(t=5)\t1.0000\t0.9400\t0.9400\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 0.94, 0.06]\n",
      "T=5\tt=3\tN1=16\tN2=16\tN=9\tjac=0.39\t\n",
      "\tdisable\t(t=5)\t1.0000\t0.0000\t0.0000\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "T=5\tt=4\tN1=16\tN2=16\tN=8\tjac=0.33\t\n",
      "\tdisable\t(t=5)\t1.0000\t0.9400\t0.9400\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 0.94, 0.06]\n",
      "T=5\tt=5\tN1=16\tN2=16\tN=6\tjac=0.23\t\n",
      "\tdisable\t(t=5)\t1.0000\t1.0000\t1.0000\n",
      "\tEach accuracy: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Verify counter neurons\n",
    "import neuron_mapping\n",
    "def verify_one_time_step(T, t, feature1, feature2, seq2seq, sample, real):\n",
    "    print(\"T=%d\\tt=%d\\tN1=%d\\tN2=%d\" % (T, t, len(feature1), len(feature2)), end=\"\\t\")\n",
    "    neuron_mapping.evaluate_intersection(feature1, feature2, verbose=2)\n",
    "    feature = neuron_mapping.get_intersection(feature1, feature2)\n",
    "    print(\"\\n\", end=\"\\t\")\n",
    "    pred = verification.verify_decoder(seq2seq, sample, feature, time_step=t, \n",
    "                                       mode=\"disable\", replace_by=\"last_h\", verbose=2)\n",
    "    evaluator.evaluate_autoencoder_at_time(real, pred, time_step=T, verbose=2)  \n",
    "    evaluator.evaluate_autoencoder_token(real, pred, token=3)\n",
    "    \n",
    "    \n",
    "def verify_counter_one_token(token):\n",
    "    with open(os.path.join(saved_path, 'neuron_token=%d.pickle' % token), 'rb') as handle:\n",
    "        result = pickle.load(handle)\n",
    "        counter_neuron = result['counter']\n",
    "        ig_neuron = result['ig']\n",
    "        \n",
    "    for T in ig_neuron:\n",
    "        si1 = sample_getter.get_sample_by_one_condition(seq2seq.decoder_in_test, \n",
    "                                                        token=token, position=T, N=100)\n",
    "        sample = seq2seq.encoder_in_test[si1]\n",
    "        real = evaluator.get_evaluate_real(seq2seq, si1)\n",
    "        verify_original_model(seq2seq, sample, real, token, T)\n",
    "        for t in ig_neuron[T]:\n",
    "            verify_one_time_step(T, t, counter_neuron[T], ig_neuron[T][t], seq2seq, sample, real)\n",
    "        break\n",
    "        \n",
    "verify_counter_one_token(token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
